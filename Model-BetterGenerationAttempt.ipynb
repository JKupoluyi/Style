{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import pandas\n",
    "import numpy as np\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize \n",
    "import gensim \n",
    "from gensim.models import Word2Vec \n",
    "import rouge\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, LSTM, Activation, Bidirectional, Dropout, Input, concatenate, Reshape, TimeDistributed, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import Model\n",
    "import tensorflow.keras.backend as K\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>publication</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>[washington, —, congressional, republicans, ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>[after, the, bullet, shells, get, the, south, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>[when, walt, disney, ’, s, but, what, they, di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>[death, may, be, the, great, equalizer, ,, but...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>[seoul, ,, south, korea, —, although, north, k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47220</th>\n",
       "      <td>47220</td>\n",
       "      <td>BBC_tech</td>\n",
       "      <td>[bt, is, introducing, two, initiatives, from, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47221</th>\n",
       "      <td>47221</td>\n",
       "      <td>BBC_tech</td>\n",
       "      <td>[computer, users, across, the, world, more, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47222</th>\n",
       "      <td>47222</td>\n",
       "      <td>BBC_tech</td>\n",
       "      <td>[a, new, european, directive, could, if, it, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47223</th>\n",
       "      <td>47223</td>\n",
       "      <td>BBC_tech</td>\n",
       "      <td>[the, man, making, sure, us, amit, yoran, was,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47224</th>\n",
       "      <td>47224</td>\n",
       "      <td>BBC_tech</td>\n",
       "      <td>[online, role, playing, games, are, time-consu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47225 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0     publication  \\\n",
       "0               0  New York Times   \n",
       "1               1  New York Times   \n",
       "2               2  New York Times   \n",
       "3               3  New York Times   \n",
       "4               4  New York Times   \n",
       "...           ...             ...   \n",
       "47220       47220        BBC_tech   \n",
       "47221       47221        BBC_tech   \n",
       "47222       47222        BBC_tech   \n",
       "47223       47223        BBC_tech   \n",
       "47224       47224        BBC_tech   \n",
       "\n",
       "                                                 content  \n",
       "0      [washington, —, congressional, republicans, ha...  \n",
       "1      [after, the, bullet, shells, get, the, south, ...  \n",
       "2      [when, walt, disney, ’, s, but, what, they, di...  \n",
       "3      [death, may, be, the, great, equalizer, ,, but...  \n",
       "4      [seoul, ,, south, korea, —, although, north, k...  \n",
       "...                                                  ...  \n",
       "47220  [bt, is, introducing, two, initiatives, from, ...  \n",
       "47221  [computer, users, across, the, world, more, th...  \n",
       "47222  [a, new, european, directive, could, if, it, g...  \n",
       "47223  [the, man, making, sure, us, amit, yoran, was,...  \n",
       "47224  [online, role, playing, games, are, time-consu...  \n",
       "\n",
       "[47225 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_pickle('data/tokenized.pkl')\n",
    "eval_df = pd.read_pickle('data/evaluation.pkl')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sentences = list(data['content'])\n",
    "all_sentences.extend(list(eval_df['content']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Relevant publications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_publications = [\n",
    "#  'Breitbart',\n",
    "#  'CNN',\n",
    "#  'New York Times',\n",
    "#  'NPR',\n",
    "#  'Fox News',\n",
    "#  'Reuters']\n",
    "selected_publications = [\n",
    " 'Breitbart',\n",
    " 'CNN',\n",
    " 'New York Times']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BBC_business',\n",
       " 'Atlantic',\n",
       " 'BBC_entertainment',\n",
       " 'Buzzfeed News',\n",
       " 'BBC_sport',\n",
       " 'Guardian',\n",
       " 'BBC_tech',\n",
       " 'Breitbart',\n",
       " 'Business Insider',\n",
       " 'National Review',\n",
       " 'New York Post',\n",
       " 'Reuters',\n",
       " 'Fox News',\n",
       " 'New York Times',\n",
       " 'Vox',\n",
       " 'Washington Post',\n",
       " 'Talking Points Memo',\n",
       " 'NPR',\n",
       " 'CNN',\n",
       " 'BBC_politics']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_publications = list(set(data['publication']))\n",
    "all_publications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Breitbart', 'CNN', 'New York Times']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take only the contents from publications with >= 3000 samples.\n",
    "publications = [pub for pub in selected_publications if pub in all_publications and len(data[data['publication'] == pub]) >= 3000]\n",
    "publications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents = []\n",
    "for pub in publications:\n",
    "    contents.append(np.asarray(data[data['publication'] == pub]['content']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding with special Character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_seq_length = max([len(seq) for content in contents for seq in content])\n",
    "max_seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_token = '~?@_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for content in contents:\n",
    "    for seq in content:\n",
    "        seq.extend([end_token] * (max_seq_length - len(seq)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_seq_length = max([len(seq) for content in contents for seq in content])\n",
    "max_seq_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "word2vec = gensim.models.Word2Vec(all_sentences, min_count = 1,  \n",
    "                              size = word_dim, window = 5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between 'congress' and 'senate' - CBOW :  0.7506351\n",
      "Cosine similarity between 'congress' and 'house' - CBOW :  0.62278795\n"
     ]
    }
   ],
   "source": [
    "print(\"Cosine similarity between 'congress' \" + \n",
    "               \"and 'senate' - CBOW : \", \n",
    "    word2vec.wv.similarity('congress', 'senate')) \n",
    "      \n",
    "print(\"Cosine similarity between 'congress' \" +\n",
    "                 \"and 'house' - CBOW : \", \n",
    "    word2vec.wv.similarity('congress', 'house')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.2737055 , -0.0815997 , -0.40515476,  0.10907958, -0.10488369,\n",
       "       -0.46514127,  0.3546361 , -0.49898246, -0.13679565, -0.95021194,\n",
       "        0.11053801,  0.28043687,  0.39044622,  0.18986215,  0.31135228,\n",
       "        0.65644604, -0.53040445,  0.09304625, -0.33855414,  1.5273463 ,\n",
       "       -1.550524  ,  0.8062989 ,  0.27642545, -0.655483  ,  0.59252894,\n",
       "       -0.29950106, -0.10941707, -1.2045021 , -0.7059632 ,  0.05883586,\n",
       "        0.27209347, -0.7489524 , -0.28490993, -0.5156418 ,  0.11626618,\n",
       "       -0.3572677 ,  0.03211268,  0.07818181, -0.51545733, -0.13020003,\n",
       "        0.1085882 , -1.5130123 ,  0.297752  , -0.5476296 ,  0.37076122,\n",
       "        0.8633128 , -0.20785286, -0.68780774,  0.73181003, -0.8301219 ,\n",
       "        0.05571607, -0.42777744, -0.12656578,  0.7455623 ,  0.36209732,\n",
       "       -0.32334244, -0.31440073,  0.4286173 , -1.4040293 ,  0.34348148,\n",
       "        0.05970663, -0.36402565, -0.15024659,  0.07058263,  0.5764989 ,\n",
       "        0.985047  ,  0.57990754,  1.5233004 ,  1.2298111 , -0.22801913,\n",
       "       -0.4920899 , -0.24267499,  0.58051795,  0.69041365, -0.21854842,\n",
       "        0.02109715,  0.7593805 ,  0.29873502, -0.08461803,  1.1381595 ,\n",
       "        0.3673395 ,  0.36424753,  0.57372564,  0.15777108,  0.20087793,\n",
       "        0.41798577,  0.66633093, -0.67897594, -0.91672003, -0.8039592 ,\n",
       "        0.16521865, -0.45108184,  1.1792547 , -0.18628389,  0.49541008,\n",
       "       -0.6159321 ,  0.3487106 ,  0.06702092, -0.42541516,  0.29356983],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec.wv['congressional']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('congressional', 1.0000001192092896),\n",
       " ('senate', 0.8786221146583557),\n",
       " ('judiciary', 0.8456677198410034),\n",
       " ('committee', 0.8444260954856873),\n",
       " ('conservative', 0.8296844959259033),\n",
       " ('gop', 0.821047842502594),\n",
       " ('liberal', 0.8202149868011475),\n",
       " ('lawmakers', 0.8164830803871155),\n",
       " ('272-219', 0.8096722364425659),\n",
       " ('governors', 0.8080213665962219)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec.wv.similar_by_vector(word2vec.wv['congressional'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents = np.asarray(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = np.zeros(shape=(contents.shape[0], contents.shape[1], max_seq_length, word_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(contents.shape[0]):\n",
    "    for j in range(contents.shape[1]):\n",
    "        for k in range(max_seq_length):\n",
    "            samples[i, j, k, :] = word2vec.wv[contents[i, j][k]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO use closest cosine distance to find output word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciton Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squareError(xTrue, xPred):\n",
    "    return K.square(xTrue - xPred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstructionLoss(sample, encoder, decoder, f_w, weight): # (L_1 from the paper)\n",
    "    return K.mean(squareError(sample, decode_sequence(encoder(sample), decoder, sample.shape[1], sample.shape[2]))) + K.mean(weight*K.log(f_w(encoder(sample))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divergenceLoss(f_w, encoder, sample, z_j, n_j): # Mean of log f_w(E_theta_i(x_j)) + log (1-f_w(z_j, n_j)) from the paper (L_2).\n",
    "    return K.mean(K.log(f_w(encoder(sample)))) + K.mean(K.log(1 - f_w(z_j + n_j)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(data, domain, num_samples):\n",
    "    N = data.shape[1]\n",
    "    return tf.convert_to_tensor(data[domain, np.random.choice(N, num_samples, replace=True),:,:], dtype=tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Currently just doing a restriction to the last z variables, might want to do a matrix multiplication?\n",
    "# pi_Z from the paper. projects a latent distribution in (z, n) to z\n",
    "def projectZ(encoded):\n",
    "    return encoded[0:2] # take zs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def projectN(encoded):\n",
    "    return encoded[2:4] # take ns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # takes in two inputs, n and z, and outputs samples.\n",
    "# def createDecoder(z_dims, n_dims, time_steps, output_dims):\n",
    "#     # TODO MAYBE: Add in more regularization or different than dropout?\n",
    "\n",
    "#     z_inputs = Input(shape=(z_dims,))\n",
    "#     n_inputs = Input(shape=(n_dims,))\n",
    "#     inputs = concatenate([z_inputs, n_inputs])\n",
    "# #     # 150 is arbitrary rn...\n",
    "# #     dense = Dense(150)(inputs)\n",
    "#     dense = Dense(time_steps*output_dims)(inputs)\n",
    "#     reshape = Reshape((time_steps, output_dims))(dense)\n",
    "#     # TODO Reshape to enforce time_steps?\n",
    "#     bilstm = Bidirectional(LSTM(64, activation='tanh', return_sequences=True))(reshape)\n",
    "#     bilstm = Dropout(0.2)(bilstm)\n",
    "#     bilstm = Bidirectional(LSTM(64, activation='tanh', return_sequences=False))(bilstm)\n",
    "#     bilstm = Dropout(0.2)(bilstm)\n",
    "    \n",
    "#     dense = Dense(time_steps*output_dims, activation='linear')(bilstm)\n",
    "#     outputs = Reshape((time_steps, output_dims))(dense)\n",
    "    \n",
    "#     model = Model(inputs=[z_inputs, n_inputs], outputs=outputs)\n",
    "    \n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createEncoder(time_steps, input_num, z_dims, n_dims):\n",
    "    # Define an input sequence and process it.\n",
    "    encoder_inputs = Input(shape=(time_steps, input_num))\n",
    "    z_encoder = LSTM(z_dims, return_state=True)\n",
    "    n_encoder = LSTM(n_dims, return_state=True)\n",
    "    \n",
    "    z_encoder_outputs, z_state_h, z_state_c = z_encoder(encoder_inputs)\n",
    "    n_encoder_outputs, n_state_h, n_state_c = n_encoder(encoder_inputs)\n",
    "    \n",
    "    # We discard `encoder_outputs` and only keep the states.\n",
    "    z_encoder_states = [z_state_h, z_state_c]\n",
    "    n_encoder_states = [n_state_h, n_state_c]\n",
    "    \n",
    "    model = Model(inputs=encoder_inputs, outputs=z_encoder_states + n_encoder_states)\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDecoder(z_dims, n_dims, time_steps, output_dims):\n",
    "    # Set up the decoder, using `encoder_states` as initial state.\n",
    "    decoder_inputs = Input(shape=(1, output_dims,))\n",
    "    \n",
    "    z_state_h = Input(shape=(z_dims,))\n",
    "    z_state_c = Input(shape=(z_dims,))\n",
    "    n_state_h = Input(shape=(n_dims,))\n",
    "    n_state_c = Input(shape=(n_dims,))\n",
    "    \n",
    "    z_encoder_states = [z_state_h, z_state_c]\n",
    "    n_encoder_states = [n_state_h, n_state_c]\n",
    "    \n",
    "    # We set up our decoder to return full output sequences,\n",
    "    # and to return internal states as well. We don't use the \n",
    "    # return states in the training model, but we will use them in inference.\n",
    "    z_decoder_lstm = LSTM(z_dims, return_sequences=True, return_state=True)\n",
    "    n_decoder_lstm = LSTM(n_dims, return_sequences=True, return_state=True)\n",
    "    z_decoder_outputs, z_state_h, z_state_c = z_decoder_lstm(decoder_inputs,\n",
    "                                         initial_state=z_encoder_states)\n",
    "    n_decoder_outputs, n_state_h, n_state_c = n_decoder_lstm(decoder_inputs,\n",
    "                                         initial_state=n_encoder_states)\n",
    "    \n",
    "    decoder_outputs = concatenate([z_decoder_outputs, n_decoder_outputs])\n",
    "    \n",
    "    z_decoder_states = [z_state_h, z_state_c]\n",
    "    n_decoder_states = [n_state_h, n_state_c]\n",
    "    \n",
    "    decoder_dense = Dense(output_dims, activation='linear')\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    \n",
    "    model = Model(inputs=[decoder_inputs] + z_encoder_states + n_encoder_states,\n",
    "                  outputs=[decoder_outputs] + z_decoder_states + n_decoder_states)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createEncDecModel(encoder, decoder, time_steps, dims):\n",
    "    encoder_inputs = Input(shape=(time_steps, dims))\n",
    "    decoder_inputs = Input(shape=(1, dims,))\n",
    "    \n",
    "    enc = encoder(encoder_inputs)\n",
    "    dec = createDecoder(decoder_inputs + enc)\n",
    "    model = Model(inputs = [encoder_inputs, decoder_inputs], outputs = dec)\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(encoder_outputs, decoder, time_steps, dims):\n",
    "    batch_size = encoder_outputs[0].shape[0]\n",
    "    \n",
    "    states_value = encoder_outputs\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((batch_size, 1, dims))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "#     target_seq[0, 0, target_token_index['\\t']] = 1.\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = np.zeros((batch_size, time_steps, dims))\n",
    "    \n",
    "    index = 0\n",
    "    while index < time_steps:\n",
    "        output_vec, z_state_h, z_state_c, n_state_h, n_state_c = decoder.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        decoded_sentence[:, index, :] = output_vec.reshape((batch_size, dims))\n",
    "\n",
    "        \n",
    "            \n",
    "            \n",
    "        target_seq = np.zeros((batch_size, 1, dims))\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            \n",
    "            # Update the target sequence (of length 1).\n",
    "            word = word2vec.wv.similar_by_vector(output_vec[i, 0, :])[0][0]\n",
    "\n",
    "            target_seq[i, 0, :] = word2vec.wv[word]\n",
    "\n",
    "        # Update states\n",
    "        states_value = [z_state_h, z_state_c, n_state_h, n_state_c]\n",
    "        index += 1\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def createEncoder(time_steps, input_num, z_dims, n_dims):\n",
    "#     # TODO MAYBE: Add in more regularization or different than dropout?\n",
    "#     inputs = Input(shape=(time_steps, input_num,))\n",
    "#     bilstm = Bidirectional(LSTM(64, activation='tanh', return_sequences=True))(inputs)\n",
    "#     bilstm = Dropout(0.2)(bilstm)\n",
    "#     dense = Bidirectional(LSTM(64, activation='tanh', return_sequences=False))(bilstm)\n",
    "#     dense = Dropout(0.2)(dense)\n",
    "#     z_output = Dense(z_dims, activation='linear')(dense)\n",
    "#     n_output = Dense(n_dims, activation='linear')(dense)\n",
    "    \n",
    "#     model = Model(inputs=inputs, outputs=[z_output, n_output])\n",
    "    \n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDiscriminator(z_dims, n_dims):\n",
    "    \n",
    "    z_inputs_h = Input(shape=(z_dims,))\n",
    "    z_inputs_c = Input(shape=(z_dims,))\n",
    "    n_inputs_h = Input(shape=(n_dims,))\n",
    "    n_inputs_c = Input(shape=(n_dims,))\n",
    "    \n",
    "    inputs = concatenate([z_inputs_h, z_inputs_c, n_inputs_h, n_inputs_c])\n",
    "    \n",
    "    # 150, 100 is arbitrary rn...\n",
    "    dense = Dense(150, activation='relu')(inputs)\n",
    "    dense = Dense(100, activation='relu')(dense)\n",
    "    output = Dense(1, activation='sigmoid')(dense)\n",
    "    \n",
    "    model = Model(inputs=[z_inputs_h, z_inputs_c, n_inputs_h, n_inputs_c], outputs=output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 5e-4\n",
    "enc_optimizer = tf.keras.optimizers.Adam(lr)\n",
    "dec_optimizer = tf.keras.optimizers.Adam(lr)\n",
    "disc_optimizer = tf.keras.optimizers.Adam(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When $P_Z$ is known... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# k is num of domains.\n",
    "# encoders is a list of encoders.\n",
    "# decoders is list of decoders.\n",
    "# samples is a K x N x Timesteps x dim, array of samples, where the 0th index is the domain,\n",
    "# the 1th index is the # of the sample in that domain, 2th index is the # timesteps per sequence, 3th index is the #\n",
    "# of dimensions at each timestep\n",
    "# original_domains is a list of the original domains P_z was derived from.\n",
    "\n",
    "# Currently assuming P_Z is known. Must approximate P_Z first.\n",
    "def trainAutoencodersWithPz(samples, encoders, decoders, discriminator, num_samples, original_domains, epochs=10, weight=1.0):\n",
    "    N = samples.shape[1]\n",
    "    k = samples.shape[0]\n",
    "        \n",
    "    \n",
    "    for i in range(k):\n",
    "        if i not in original_domains:\n",
    "            original_domain = np.random.choice(original_domains)\n",
    "            encoder = encoders[i]\n",
    "            decoder = decoders[i]\n",
    "            original_encoder = encoders[original_domain]\n",
    "            epoch = 0\n",
    "            while(epoch < epochs): # TOOD: could also do until some convergence criteria.\n",
    "                p_Xi_samples = sample(samples, i, num_samples)\n",
    "                p_Z_samples = projectZ(original_encoder(sample(samples, original_domain, num_samples)))\n",
    "                p_Ni_samples = projectN(encoder(sample(samples, i, num_samples)))\n",
    "\n",
    "                with tf.GradientTape() as enc_tape, tf.GradientTape() as dec_tape, tf.GradientTape() as disc_tape:\n",
    "\n",
    "                    reconstruction_loss = reconstructionLoss(p_Xi_samples, encoder, decoder, discriminator, weight)\n",
    "\n",
    "                    # negative b/c gradient ascent.\n",
    "                    divergence_loss = -1 * divergenceLoss(discriminator, encoder, p_Xi_samples, p_Z_samples, p_Ni_samples)\n",
    "\n",
    "                gradients_of_encoder = enc_tape.gradient(reconstruction_loss, encoder.trainable_variables)\n",
    "                gradients_of_decoder = dec_tape.gradient(reconstruction_loss, decoder.trainable_variables)\n",
    "                gradients_of_discriminator = disc_tape.gradient(divergence_loss, discriminator.trainable_variables)\n",
    "\n",
    "\n",
    "                enc_optimizer.apply_gradients(zip(gradients_of_encoder, encoder.trainable_variables))\n",
    "                dec_optimizer.apply_gradients(zip(gradients_of_decoder, decoder.trainable_variables))\n",
    "                disc_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "                \n",
    "                print('Domain {}, Epoch {}:\\n\\tReconstruction Loss: {}\\n\\tDivergence Loss: {}'.format(i, epoch+1, reconstruction_loss, divergence_loss))\n",
    "                epoch+=1\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When $P_Z$ is unknown...\n",
    "\"A straight-forward approach for learning the latent distribution PZ is to train a regularized autoencoder on data from a\n",
    "single representative domain. However, such a representation could potentially capture variability that is specific to\n",
    "that one domain. To learn a more invariant latent representation, we propose the following extension of our autoencoder\n",
    "framework. The basic idea is to alternate between training\n",
    "multiple autoencoders until they agree on a latent representation that is effective for their respective domains. This is\n",
    "particularly relevant for applications to biology; for example, often one is interested in learning a latent representation\n",
    "that integrates all of the data modalities.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# k is num of domains.\n",
    "# encoders is a list of encoders.\n",
    "# decoders is list of decoders.\n",
    "# samples is a K x N x Timesteps x dim, array of samples, where the 0th index is the domain,\n",
    "# the 1th index is the # of the sample in that domain, 2th index is the # timesteps per sequence, 3th index is the #\n",
    "# of dimensions at each timestep\n",
    "# domains is a list of the domains we are currently training over.\n",
    "\n",
    "def trainAutoencodersInitial(samples, encoders, decoders, discriminator, num_samples, domains, epochs=10, weight=1.0):\n",
    "    N = samples.shape[1]\n",
    "    k = samples.shape[0]\n",
    "    \n",
    "    for i in domains:\n",
    "        encoder = encoders[i]\n",
    "        decoder = decoders[i]\n",
    "        for j in domains:\n",
    "            if i != j:\n",
    "                j_encoder = encoders[j]\n",
    "                epoch = 0\n",
    "                while(epoch < epochs): # TOOD: could also do until some convergence criteria.\n",
    "                    p_Xi_samples = sample(samples, i, num_samples)\n",
    "                    p_Zj_samples = projectZ(j_encoder(sample(samples, j, num_samples)))\n",
    "                    p_Ni_samples = projectN(encoder(sample(samples, i, num_samples)))\n",
    "\n",
    "                    with tf.GradientTape() as enc_tape, tf.GradientTape() as dec_tape, tf.GradientTape() as disc_tape:\n",
    "\n",
    "                        reconstruction_loss = reconstructionLoss(p_Xi_samples, encoder, decoder, discriminator, weight)\n",
    "#                         print(p_Xi_samples)\n",
    "\n",
    "                        # negative b/c gradient ascent.\n",
    "                        divergence_loss = -1 * divergenceLoss(discriminator, encoder, p_Xi_samples, p_Zj_samples, p_Ni_samples)\n",
    "#                         print(p_Zj_samples)\n",
    "#                         print(p_Ni_samples)\n",
    "                        \n",
    "                    gradients_of_encoder = enc_tape.gradient(reconstruction_loss, encoder.trainable_variables)\n",
    "                    gradients_of_decoder = dec_tape.gradient(reconstruction_loss, decoder.trainable_variables)\n",
    "                    gradients_of_discriminator = disc_tape.gradient(divergence_loss, discriminator.trainable_variables)\n",
    "            \n",
    "\n",
    "                    enc_optimizer.apply_gradients(zip(gradients_of_encoder, encoder.trainable_variables))\n",
    "                    dec_optimizer.apply_gradients(zip(gradients_of_decoder, decoder.trainable_variables))\n",
    "                    disc_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "                    \n",
    "                    print('Domain {}, Epoch {}:\\n\\tReconstruction Loss: {}\\n\\tDivergence Loss: {}'.format(i, epoch+1, reconstruction_loss, divergence_loss))\n",
    "                    epoch+=1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples is a K x N x Timesteps x dim, array of samples, where the 0th index is the domain,\n",
    "# the 1th index is the # of the sample in that domain, 2th index is the # timesteps per sequence, 3th index is the #\n",
    "# of dimensions at each timestep\n",
    "\n",
    "def initModel(samples, z_dims, n_dims):\n",
    "    \n",
    "    k = samples.shape[0]\n",
    "    N = samples.shape[1]\n",
    "    time_steps = samples.shape[2]\n",
    "    dim = samples.shape[3]\n",
    "    \n",
    "    \n",
    "    \n",
    "    discriminator = createDiscriminator(z_dims, n_dims)\n",
    "    \n",
    "    encoders = []\n",
    "    decoders = []\n",
    "    \n",
    "    for i in range(k):\n",
    "        encoders.append(createEncoder(time_steps, dim, z_dims, n_dims))\n",
    "        decoders.append(createDecoder(z_dims, n_dims, time_steps, dim))\n",
    "    \n",
    "    return encoders, decoders, discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(start_sequences, samples, encoders, decoders, start_domain, end_domain):\n",
    "    time_steps = start_sequences.shape[1]\n",
    "    dims = start_sequences.shape[2]\n",
    "    \n",
    "    N = samples.shape[1]\n",
    "    print(start_sequences.shape)\n",
    "    num_samples = start_sequences.shape[0]\n",
    "    \n",
    "    start_encoder = encoders[start_domain]\n",
    "    end_encoder = encoders[end_domain]\n",
    "    end_decoder = decoders[end_domain]\n",
    "    \n",
    "    z = projectZ(start_encoder(start_sequences))\n",
    "    n = projectN(end_encoder(sample(samples, end_domain, num_samples)))\n",
    "    \n",
    "    end_sequences = decode_sequence(z+n, end_decoder, time_steps, dims)\n",
    "    return end_sequences\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vecSeqToSentence(sequence):\n",
    "    sequence = K.eval(sequence)\n",
    "    sentence = []\n",
    "    for i in range(sequence.shape[0]):\n",
    "        word = sequence[i,:]\n",
    "#         print(word)\n",
    "#         print(word2vec.wv.similar_by_vector(word))\n",
    "        sentence.append(word2vec.wv.similar_by_vector(word)[0][0])\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dims = 64 # len(n)\n",
    "z_dims = 64 # len(Z)\n",
    "\n",
    "num_epochs = 2\n",
    "num_samples = 128\n",
    "\n",
    "weight = 1\n",
    "\n",
    "original_domains = [0, 1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples = tf.convert_to_tensor(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoders, decoders, discriminator = initModel(samples, z_dims, n_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_52\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_169 (InputLayer)          [(None, 50, 100)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_88 (LSTM)                  [(None, 64), (None,  42240       input_169[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_89 (LSTM)                  [(None, 64), (None,  42240       input_169[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 84,480\n",
      "Trainable params: 84,480\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoders[0].summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original First Sentence from 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'on tuesday ’ s broadcast ” zeleny said , “ and she ’ s having a difficult time in federal prison , no question . ~?@_ ~?@_ ~?@_ ~?@_ ~?@_ ~?@_ ~?@_ ~?@_ ~?@_ ~?@_ ~?@_ ~?@_ ~?@_ ~?@_ ~?@_ ~?@_ ~?@_ ~?@_ ~?@_ ~?@_ ~?@_ ~?@_ ~?@_ ~?@_ ~?@_'"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(contents[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 50, 100)\n"
     ]
    }
   ],
   "source": [
    "seq = tf.convert_to_tensor(np.asarray([samples[0, 0, :, :]]), dtype=tf.float32)\n",
    "translation = translate(seq, samples, encoders, decoders, original_domains[0], original_domains[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original First Sentence from 0 translated to 1 before Training (Random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['faring', 'faring', 'faring', 'faring', 'faring', 'faring', 'antinuclear', 'antinuclear', 'antinuclear', 'antinuclear', 'jails', 'jails', 'jails', 'jails', 'jails', 'jails', 'specimens', 'specimens', 'buckfield', 'buckfield', 'buckfield', 'cementing', 'cementing', 'cementing', 'bookmark', 'cementing', 'bookmark', 'cementing', 'cementing', 'bookmark', 'cementing', 'cementing', 'cementing', 'ahsha', 'cementing', 'terrorist.', 'spartan', 'annihilation', 'animate', 'hollow', 'animate', 'hollow', 'shipworm', 'gasp', 'canes', 'symptomatic', 'symptomatic', 'symptomatic', 'continual', 'dehumanizing']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vecSeqToSentence(translation[0,:,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No gradients provided for any variable: ['lstm_90/kernel:0', 'lstm_90/recurrent_kernel:0', 'lstm_90/bias:0', 'lstm_91/kernel:0', 'lstm_91/recurrent_kernel:0', 'lstm_91/bias:0', 'dense_48/kernel:0', 'dense_48/bias:0'].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-171-bd9778458573>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainAutoencodersInitial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_domains\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-160-db1d014bb6e7>\u001b[0m in \u001b[0;36mtrainAutoencodersInitial\u001b[0;34m(samples, encoders, decoders, discriminator, num_samples, domains, epochs, weight)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m                     \u001b[0menc_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients_of_encoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m                     \u001b[0mdec_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients_of_decoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m                     \u001b[0mdisc_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients_of_discriminator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars, name)\u001b[0m\n\u001b[1;32m    425\u001b[0m       \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mnone\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mvariables\u001b[0m \u001b[0mhave\u001b[0m \u001b[0mgradients\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m     \"\"\"\n\u001b[0;32m--> 427\u001b[0;31m     \u001b[0mgrads_and_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_filter_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m     \u001b[0mvar_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m_filter_grads\u001b[0;34m(grads_and_vars)\u001b[0m\n\u001b[1;32m   1023\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfiltered\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m     raise ValueError(\"No gradients provided for any variable: %s.\" %\n\u001b[0;32m-> 1025\u001b[0;31m                      ([v.name for _, v in grads_and_vars],))\n\u001b[0m\u001b[1;32m   1026\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mvars_with_empty_grads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m     logging.warning(\n",
      "\u001b[0;31mValueError\u001b[0m: No gradients provided for any variable: ['lstm_90/kernel:0', 'lstm_90/recurrent_kernel:0', 'lstm_90/bias:0', 'lstm_91/kernel:0', 'lstm_91/recurrent_kernel:0', 'lstm_91/bias:0', 'dense_48/kernel:0', 'dense_48/bias:0']."
     ]
    }
   ],
   "source": [
    "trainAutoencodersInitial(samples, encoders, decoders, discriminator, num_samples, original_domains, epochs=num_epochs, weight=weight)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original First Sentence from 0 translated to 1 after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translation = translate(seq, samples, encoders, decoders, original_domains[0], original_domains[1])\n",
    "vecSeqToSentence(translation[0,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainAutoencodersWithPz(samples, encoders, decoders, discriminator, num_samples, original_domains, epochs=num_epochs, weight=weight)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original First Sentence from 0 translated to 2 after Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translation = translate(seq, samples, encoders, decoders, 0, 2)\n",
    "vecSeqToSentence(translation[0,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation with Rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents = []\n",
    "for pub in publications:\n",
    "    contents.append(np.asarray(eval_df[eval_df['publication'] == pub]['content']))\n",
    "    \n",
    "for content in contents:\n",
    "    for seq in content:\n",
    "        seq.extend([end_token] * (max_seq_length - len(seq)))\n",
    "    \n",
    "contents = np.asarray(contents)\n",
    "samples = np.zeros(shape=(contents.shape[0], contents.shape[1], max_seq_length, word_dim))\n",
    "\n",
    "for i in range(contents.shape[0]):\n",
    "    for j in range(contents.shape[1]):\n",
    "        for k in range(max_seq_length):\n",
    "            samples[i, j, k, :] = word2vec.wv[contents[i, j][k]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detok = TreebankWordDetokenizer()\n",
    "\n",
    "evaluator = rouge.Rouge(metrics=['rouge-n', 'rouge-l', 'rouge-w'],\n",
    "                        max_n=4,\n",
    "                        limit_length=True,\n",
    "                        length_limit=100,\n",
    "                        length_limit_type='words',\n",
    "                        apply_avg=False,\n",
    "                        apply_best=True,\n",
    "                        alpha=0.5, # Default F1_score\n",
    "                        weight_factor=1.2,\n",
    "                        stemming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateOnArticles(articles, encoder, decoder):\n",
    "    translated = decode_sequence(encoder(tf.convert_to_tensor(articles, dtype=tf.float32)), decoder, articles.shape[1], articles.shape[2])\n",
    "       \n",
    "    original_sentences = [vecSeqToSentence(tokens) for tokens in articles]\n",
    "    \n",
    "    translated_sentences = [vecSeqToSentence(tokens) for tokens in translated]\n",
    "    \n",
    "    scores = evaluator.get_scores(translated_sentences, original_sentences)\n",
    "    \n",
    "    for metric, results in sorted(scores.items(), key=lambda x: x[0]):\n",
    "        print('\\t{}:\\t{}: {:5.2f}\\t{}: {:5.2f}\\t{}: {:5.2f}'.format(metric, 'P', 100.0 * results['p'], 'R', 100.0 * results['r'], 'F1', 100.0 * results['f']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(articles, encoders, decoders):\n",
    "    \n",
    "    for i in range(len(selected_publications)):\n",
    "        for j in range(len(selected_publications)):\n",
    "            if (i != j):\n",
    "                pub1=publications[i]\n",
    "                pub2=publications[j]\n",
    "                #source_articles = articles_df.loc[articles_df['publication'] == pub1]['content'].tolist()\n",
    "                source_articles = articles[i]\n",
    "                \n",
    "                print(pub1,\"to\",pub2)\n",
    "                evaluateOnArticles(source_articles, encoders[i], decoders[j])\n",
    "                print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(samples, encoders, decoders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a6fa0bf60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses1 = [10, 9, 6, 3, 2, 2, 2, 1, 1, 1, 1]\n",
    "losses2 = [11, 10, 7, 6, 5, 5, 3, 3, 2, 1, 1]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plotLosses(domain, recLosses, divLosses):\n",
    "\n",
    "    plt.figure(figsize=(16, 6))\n",
    "    plt.title('Loss for Training Domain {} Autoencoder'.format(domain))\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.plot(range(len(recLosses)), recLosses, range(len(divLosses)), divLosses)\n",
    "    plt.legend(['Reconstruction', 'Divergence'])\n",
    "    plt.show()\n",
    "\n",
    "plotLosses(5, losses1, losses2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
